2019-08-29 00:28:56,961 - tensorflow - INFO - Using config: {'_model_dir': 's3://jiayun.spark.data/wangqi/wide_deep/v1/logData/wide_and_deep_traditional_attention', '_tf_random_seed': 77887, '_save_summary_steps': 400, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': log_device_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 1, '_log_step_count_steps': 400, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0xb46847d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
2019-08-29 00:28:56,965 - tensorflow - INFO - Build estimator: <tensorflow_estimator.python.estimator.estimator.Estimator object at 0xb46847550>
2019-08-29 00:28:56,966 - tensorflow - INFO - Not using Distribute Coordinator.
2019-08-29 00:28:56,967 - tensorflow - INFO - Running training and evaluation locally (non-distributed).
2019-08-29 00:28:56,969 - tensorflow - INFO - Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.
